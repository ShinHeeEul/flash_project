{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f415fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4414ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "#에러 발생시 위 코드 주석으로 대체\n",
    "#from transformers import WarmupLinearSchedule as get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc45d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkGPU():\n",
    "    n_devices = torch.cuda.device_count()\n",
    "    print(n_devices)\n",
    "    for i in range(n_devices):\n",
    "        print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc1a11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def readFile():\n",
    "    #데이터 읽어오기, csv파일 위치 추가\n",
    "    chatbot_data = pd.read_csv(\"CSV 파일 위치\")\n",
    "    #데이터 밸런싱을 신경써서 섞기\n",
    "    chatbot_data_shuffled = chatbot_data.sample(frace=1).reset_index(drop=True)\n",
    "    #훈련데이터와 테스트데이터 나누기\n",
    "    train = chatbot_data_shuffled[:9000]\n",
    "    test = chatbot_data_shuffled[9000:]\n",
    "    #문장의 앞마다 [CLS], 문장 종료는 [SEP]를 붙여 인식시킨다.\n",
    "    #훈련데이터 인식과정\n",
    "    sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train.Q]\n",
    "    labels = train['label'].values     \n",
    "    preProcess(senetences, labels, \"train\")\n",
    "    #test데이터 인식과정\n",
    "    sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in test.Q]\n",
    "    labels = test['label'].values\n",
    "    preProcess(senetences, labels, \"test\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b7ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#설명\n",
    "\n",
    "##################################################\n",
    "#단어를 토큰으로 만든뒤 정수 인코딩, 패딩 과정 수행\n",
    "#정수 인코딩 : 텍스트를 숫자로 바꾸는 기법\n",
    "## -> 각 단어를 고유한 정수에 매핑시키는 작업\n",
    "# 패딩 과정 : 문장의 길이를 하나로 통일하는 과정\n",
    "## -> 처리의 간편화를 위함, 하나로 통일할 때 부족한 배열의 값을 0으로 채우는 걸 제로 패딩이라고 함.\n",
    "## -> 여기서는 최대 128까지로 설정\n",
    "#기본적으로 자주 등장하는 단어를 단어 집합에 추가\n",
    "##################################################  \n",
    "##################################################\n",
    "## 어텐션이란? \n",
    "#쿼리가 주어졌을 때, 이 쿼리와 \n",
    "#여러 개의 키와의 유사도를 각각 구하고,\n",
    "#구한 유사도를 가중치로 설정하여 각각의 값을 구한 뒤\n",
    "#이 값들을 모두 가중합하여 반환하는 함수\n",
    "######\n",
    "#단어 벡터에 대해 쿼리, 키 값의 가중치 행렬을 곱해주어\n",
    "#쿼리, 키, 값 벡터를 얻어낸다.\n",
    "#그 후 쿼리 벡터에 대해 어텐션 스코어를 구하고,\n",
    "#이를 이용하여 모든 값 벡터를 가중합하여 어텐션 값을 구하게 된다.\n",
    "##################################################\n",
    "## 0 값을 가지는 패딩 토큰에 대해서 \n",
    "## 어텐션 연산을 불필요하게 수행하지 않도록 단어와 \n",
    "## 패딩 토큰을 구분할 수 있게 알려주는 것\n",
    "# 패딩된 데이터가 있을 때 패딩된 값은 0, 패딩되지 않은 단어는 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "308ae515",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test set 전처리\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "def getTokenizer():\n",
    "        global tokenizer\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "\n",
    "def preProcess(senetences, labels, mode):\n",
    "    input_ids, attention_masks = tokenizing(sentences)\n",
    "    \n",
    "    # 파이토치 텐서로 변환\n",
    "    if mode == \"test\": seperateDataTest(input_ids, labels, attention_masks)\n",
    "    elif mode == \"train\": seperateDataTrain(input_ids, labels, attention_masks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a206e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizing(sentences):\n",
    "    # Word 토크나이저 토큰화\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 시퀀스 설정 및 정수 인덱스 변환 & 패딩\n",
    "    MAX_LEN = 128\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크\n",
    "    attention_masks = []\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "        \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e539f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperateDataTest(input_ids, labels, attention_masks):\n",
    "    test_inputs = torch.tensor(input_ids)\n",
    "    test_labels = torch.tensor(labels)\n",
    "    test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    # 배치 사이즈 설정 및 데이터 설정\n",
    "    batch_size = 32\n",
    "    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "    test_sampler = RandomSampler(test_data)\n",
    "    global test_dataloader\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c6621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperateDataTrain(input_ids, labels, attention_masks):\n",
    "    #훈련셋과 검증셋, 훈련 라벨과 검증 라벨 생성\n",
    "    #input_ids와 labels를 분리\n",
    "    train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state= 2000, test_size=0.1)\n",
    "\n",
    "    #어텐션마스크를 분리\n",
    "    train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                     random_state=2000,\n",
    "                                     test_size=0.1)\n",
    "\n",
    "    #파이토치 텐서로 전환\n",
    "    train_inputs = torch.tensor(train_inputs)\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    train_masks = torch.tensor(train_masks)\n",
    "\n",
    "    validation_inputs = torch.tensor(validation_inputs)\n",
    "    validation_labels = torch.tensor(validation_labels)\n",
    "    validation_masks = torch.tensor(validation_masks)\n",
    "    \n",
    "    #배치사이즈를 설정하고 입력 데이터, 어텐션 마스크, 라벨을 하나의 데이터로 묶어 데이터 생성\n",
    "    batch_size = 32\n",
    "\n",
    "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    \n",
    "    global train_dataloader\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "    validation_sampler = SequentialSampler(validation_data)\n",
    "    \n",
    "    global validation_dataloader\n",
    "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0155b781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "#BERT 모델 불러오기 전 GPU 디바이스 설정\n",
    "def setGPU() :\n",
    "    if torch.cuda.is_available():    \n",
    "        device = torch.device(\"cuda\")\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrain된 BERT 모델 불러오기\n",
    "def getBERT() :\n",
    "    setGPU()\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "    model.cuda()\n",
    "    #하이퍼 파라미터\n",
    "    # 옵티마이저\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률(learning rate)\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "    # 에폭수\n",
    "    epochs = 4\n",
    "\n",
    "    # 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # 스케줄러 생성\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "    trainModel(model, epochs, optimizer, scheduler)\n",
    "    testModel(model, epochs, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flatAccuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    \n",
    "    \n",
    "# 시간 표시 함수\n",
    "def formatTime(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae60a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "##모델 학습\n",
    "\n",
    "#랜덤시드 고정\n",
    "def trainModel(model, epochs, optimizer, scheduler) :\n",
    "    seed_val = 42\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    #그래디언트 초기화\n",
    "    model.zero_grad()\n",
    "\n",
    "    # 학습\n",
    "    for epoch_i in range(0, epochs):\n",
    "    \n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "    \n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # 시작 시간 설정\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 로스 초기화\n",
    "        total_loss = 0\n",
    "\n",
    "        # 훈련모드로 변경\n",
    "        model.train()\n",
    "        \n",
    "        # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # 경과 정보 표시\n",
    "            if step % 500 == 0 and not step == 0:\n",
    "                elapsed = formatTime(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # 배치를 GPU에 넣음\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "            # 배치에서 데이터 추출\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # Forward 수행                \n",
    "            outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "            # 로스 구함\n",
    "            loss = outputs[0]\n",
    "\n",
    "            # 총 로스 계산\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward 수행으로 그래디언트 계산\n",
    "            loss.backward()\n",
    "\n",
    "            # 그래디언트 클리핑\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "            optimizer.step()\n",
    "\n",
    "            # 스케줄러로 학습률 감소\n",
    "            scheduler.step()\n",
    "\n",
    "            # 그래디언트 초기화\n",
    "            model.zero_grad()\n",
    "\n",
    "        # 평균 로스 계산\n",
    "        avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(formatTime(time.time() - t0)))\n",
    "        \n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        #시작 시간 설정\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 평가모드로 변경\n",
    "        model.eval()\n",
    "\n",
    "        # 변수 초기화\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "        # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "        for batch in validation_dataloader:\n",
    "            # 배치를 GPU에 넣음\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "            # 배치에서 데이터 추출\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "            # 그래디언트 계산 안함\n",
    "            with torch.no_grad():     \n",
    "                # Forward 수행\n",
    "                outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "            # 로스 구함\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # CPU로 데이터 이동\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "            # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "            tmp_eval_accuracy = flatAccuracy(logits, label_ids)\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "        print(\"  Validation took: {:}\".format(formatTime(time.time() - t0)))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4877a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 테스트셋 평가\n",
    "\n",
    "def testModel(model, epochs, optimizer, scheduler):\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            elapsed = formatTime(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "        # 출력 로직과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flatAccuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"Test took: {:}\".format(formatTime(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74229991",
   "metadata": {},
   "outputs": [],
   "source": [
    "##새로운 문장 테스트\n",
    "\n",
    "# 입력 데이터 변환\n",
    "def convert_input_data(sentences):\n",
    "    input_ids, attention_masks = tokenizing(sentences)\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks\n",
    "\n",
    "# 문장 테스트\n",
    "def testSentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#일상대화 문장 추가\n",
    "#예시\n",
    "\"\"\"\n",
    "logits = test_sentences(['더 나은 학교생활 하고 싶어'])\n",
    "print(logits)\n",
    "\n",
    "if np.argmax(logits) == 1 :\n",
    "    print(\"연애 관련 대화\")\n",
    "elif np.argmax(logits) == 0 :\n",
    "    print(\"일상 대화\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c9f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n"
     ]
    }
   ],
   "source": [
    "def getModel():\n",
    "    readFile()\n",
    "    getTokenizer()\n",
    "    getBERT()\n",
    "\n",
    "#학습된 모델 가져오기\n",
    "#getModel()\n",
    "\n",
    "#새로운 문장 들어왔을 시 치매인지 아닌지 반환\n",
    "# 1이면 치매, 0이면 일반\n",
    "def newSentence(S):\n",
    "    ans = test_sentences([S])\n",
    "    return np.argmax(ans)\n",
    "\n",
    "def Test():\n",
    "    return \"TEST\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
