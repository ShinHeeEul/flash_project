{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f415fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4414ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "#에러 발생시 위 코드 주석으로 대체\n",
    "#from transformers import WarmupLinearSchedule as get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc45d04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "print(n_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad835051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_devices):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc1a11c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() missing 1 required positional argument: 'filepath_or_buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#데이터 읽어오기, csv파일 위치 추가\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m chatbot_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#데이터 밸런싱을 신경써서 섞기\u001b[39;00m\n\u001b[0;32m      7\u001b[0m chatbot_data_shuffled \u001b[38;5;241m=\u001b[39m chatbot_data\u001b[38;5;241m.\u001b[39msample(frace\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: read_csv() missing 1 required positional argument: 'filepath_or_buffer'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "#데이터 읽어오기, csv파일 위치 추가\n",
    "chatbot_data = pd.read_csv(\"CSV 파일 위치\")\n",
    "#데이터 밸런싱을 신경써서 섞기\n",
    "chatbot_data_shuffled = chatbot_data.sample(frace=1).reset_index(drop=True)\n",
    "#훈련데이터와 테스트데이터 나누기\n",
    "train = chatbot_data_shuffled[:9000]\n",
    "test = chatbot_data_shuffled[9000:]\n",
    "#문장의 앞마다 [CLS], 문장 종료는 [SEP]를 붙여 인식시킨다.\n",
    "sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train.Q]\n",
    "\n",
    "#제대로 들어갔나 확인\n",
    "#sentences[:5]\n",
    "#0과 1이 들어간 라벨 컬럼은 array에 따로 저장\n",
    "labels = train['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b7ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "#BERT에서 사용하는 토크나이저 WordPiece\n",
    "# 단어를 토큰화할 때, 단어 집합에 없는 단어는 더 쪼개서 ##을 붙여주는 방식\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\",\n",
    "                                          do_lower_case=False)\n",
    "\n",
    "#안녕하세요에 이를 적용\n",
    "#현재 단어집합에 단어가 없으므로 ##을 붙임으로써 \n",
    "#녕하세요가 어떠한 단어의 서브워드라는 것을 나타내줌\n",
    "result = tokenizer.tokenize(\"안녕하세요\")\n",
    "print(result)\n",
    "\n",
    "#WordPiece 토크나이저를 이용해 전체 데이터에 토크나이징 수행\n",
    "##################################################\n",
    "#어떤 모델이든 단어 자체를 텍스트 형식으로 입력할 수 없으니,\n",
    "#단어를 토큰으로 만든뒤 정수 인코딩, 패딩 과정 수행\n",
    "#기본적으로 자주 등장하는 단어를 단어 집합에 추가\n",
    "##################################################\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',\n",
    "                                         do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(s) for s in sentences]\n",
    "\n",
    "print(sentences[0])  #토크나이징 전\n",
    "print(tokenized_texts[0]) #토크나이징 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장의 최대 시퀀스를 설정하여 정수 인코딩과 제로 패딩을 수행\n",
    "MAX_LEN = 128 # 최대 시퀀스 길이 설정\n",
    "\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
    "                          truncating=\"post\",\n",
    "                         padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a321fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "# 어텐션 마스크\n",
    "##################################################\n",
    "## 어텐션이란? \n",
    "#쿼리가 주어졌을 때, 이 쿼리와 \n",
    "#여러 개의 키와의 유사도를 각각 구하고,\n",
    "#구한 유사도를 가중치로 설정하여 각각의 값을 구한 뒤\n",
    "#이 값들을 모두 가중합하여 반환하는 함수\n",
    "######\n",
    "#단어 벡터에 대해 쿼리, 키 값의 가중치 행렬을 곱해주어\n",
    "#쿼리, 키, 값 벡터를 얻어낸다.\n",
    "#그 후 쿼리 벡터에 대해 어텐션 스코어를 구하고,\n",
    "#이를 이용하여 모든 값 벡터를 가중합하여 어텐션 값을 구하게 된다.\n",
    "##################################################\n",
    "## 0 값을 가지는 패딩 토큰에 대해서 \n",
    "## 어텐션 연산을 불필요하게 수행하지 않도록 단어와 \n",
    "## 패딩 토큰을 구분할 수 있게 알려주는 것\n",
    "# 패딩된 데이터가 있을 때 패딩된 값은 0, 패딩되지 않은 단어는 1\n",
    "#어텐션 마스크 생성\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    atteuntion_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af824af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set을 훈련셋과 검증셋으로 분리\n",
    "#e데이터를 모두 파이토치 텐서로 변환\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = \n",
    "train_test_split(input_ids, labels, random_state= 2000, test_size=0.1)\n",
    "\n",
    "train_maks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                     random_state=2000,\n",
    "                                     test_size=0.1)\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7961d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배치사이즈를 설정하고 입력 데이터, 어텐션 마스크, 라벨을 하나의 데이터로 묶어 데이터 생성\n",
    "batch_size = 32\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308ae515",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test set 전처리\n",
    "\n",
    "# [CLS] + 문장 + [SEP]\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "\n",
    "# 라벨 데이터\n",
    "labels = test['label'].values\n",
    "\n",
    "# Word 토크나이저 토큰화\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "# 시퀀스 설정 및 정수 인덱스 변환 & 패딩\n",
    "MAX_LEN = 128\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# 어텐션 마스크\n",
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "    \n",
    "# 파이토치 텐서로 변환\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "# 배치 사이즈 설정 및 데이터 설정\n",
    "batch_size = 32\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0155b781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "#BERT 모델 불러오기 전 GPU 디바이스 설정\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrain된 BERT 모델 불러오기\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터\n",
    "# 옵티마이저\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률(learning rate)\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 4\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9f058c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    \n",
    "    \n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae60a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "##모델 학습\n",
    "\n",
    "#랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 학습\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4877a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 테스트셋 평가\n",
    "\n",
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74229991",
   "metadata": {},
   "outputs": [],
   "source": [
    "##새로운 문장 테스트\n",
    "\n",
    "# 입력 데이터 변환\n",
    "def convert_input_data(sentences):\n",
    "\n",
    "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 입력 토큰의 최대 시퀀스 길이\n",
    "    MAX_LEN = 128\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    \n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks\n",
    "\n",
    "# 문장 테스트\n",
    "def test_sentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1249fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#일상대화 문장 추가\n",
    "\n",
    "logits = test_sentences(['더 나은 학교생활 하고 싶어'])\n",
    "print(logits)\n",
    "\n",
    "if np.argmax(logits) == 1 :\n",
    "    print(\"연애 관련 대화\")\n",
    "elif np.argmax(logits) == 0 :\n",
    "    print(\"일상 대화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd62c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = test_sentences(['저녁 뭘 먹을지 추천해줘'])\n",
    "\n",
    "print(logits)\n",
    "if np.argmax(logits) == 1 :\n",
    "    print(\"연애 관련 대화\")\n",
    "elif np.argmax(logits) == 0 :\n",
    "    print(\"일상 대화\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c9f817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-4' coro=<main() running at C:\\Users\\shinheeeul\\AppData\\Local\\Temp\\ipykernel_22368\\4001136174.py:13>>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "connection handler failed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\protocol.py\", line 968, in transfer_data\n",
      "    message = await self.read_message()\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\protocol.py\", line 1038, in read_message\n",
      "    frame = await self.read_data_frame(max_size=self.max_size)\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\protocol.py\", line 1113, in read_data_frame\n",
      "    frame = await self.read_frame(max_size)\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\protocol.py\", line 1170, in read_frame\n",
      "    frame = await Frame.read(\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\framing.py\", line 69, in read\n",
      "    data = await reader(2)\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\asyncio\\streams.py\", line 723, in readexactly\n",
      "    await self._wait_for_data('readexactly')\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\asyncio\\streams.py\", line 517, in _wait_for_data\n",
      "    await self._waiter\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\asyncio\\selector_events.py\", line 854, in _read_ready__data_received\n",
      "    data = self._sock.recv(self.max_size)\n",
      "ConnectionResetError: [WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\server.py\", line 236, in handler\n",
      "    await self.ws_handler(self)\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\server.py\", line 1175, in _ws_handler\n",
      "    return await cast(\n",
      "  File \"C:\\Users\\shinheeeul\\AppData\\Local\\Temp\\ipykernel_22368\\4001136174.py\", line 7, in echo\n",
      "    async for message in websocket:\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\protocol.py\", line 497, in __aiter__\n",
      "    yield await self.recv()\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\protocol.py\", line 568, in recv\n",
      "    await self.ensure_open()\n",
      "  File \"C:\\Users\\shinheeeul\\anaconda3\\lib\\site-packages\\websockets\\legacy\\protocol.py\", line 944, in ensure_open\n",
      "    raise self.connection_closed_exc()\n",
      "websockets.exceptions.ConnectionClosedError: no close frame received or sent\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "\n",
    "\n",
    "\n",
    "async def echo(websocket, path):\n",
    "    async for message in websocket:\n",
    "        print(message)\n",
    "        # message를 분석하여 주피터 노트북으로 값을 전달하는 코드 작성\n",
    "        #분석\n",
    "        #await websocket.send_text(f\"Message text was: {data}\")\n",
    "\n",
    "async def main():\n",
    "    async with websockets.serve(echo, \"localhost\", 8765):\n",
    "        await asyncio.Future()  # 서버가 계속 실행되도록 대기\n",
    "\n",
    "# 현재 실행 중인 이벤트 루프 가져오기\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# 이벤트 루프에서 비동기 코드 실행\n",
    "loop.create_task(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3562665",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d9dda5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
