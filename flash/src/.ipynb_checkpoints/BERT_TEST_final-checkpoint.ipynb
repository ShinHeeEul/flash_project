{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f415fc93",
   "metadata": {
    "id": "f415fc93"
   },
   "outputs": [],
   "source": [
    "#-*-coding:utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6b7aafYnVfj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6b7aafYnVfj",
    "outputId": "67abb7e6-7b3c-4888-8578-c2f79ffaab03"
   },
   "outputs": [],
   "source": [
    "#!pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4414ea",
   "metadata": {
    "id": "1e4414ea"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "#에러 발생시 위 코드 주석으로 대체\n",
    "#from transformers import WarmupLinearSchedule as get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import csv\n",
    "\n",
    "from scipy.special import softmax\n",
    "#from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc45d04e",
   "metadata": {
    "id": "fc45d04e"
   },
   "outputs": [],
   "source": [
    "def checkGPU():\n",
    "    n_devices = torch.cuda.device_count()\n",
    "    print(n_devices)\n",
    "    for i in range(n_devices):\n",
    "        print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1a11c3",
   "metadata": {
    "id": "bc1a11c3"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def readFile():\n",
    "    #데이터 읽어오기, csv파일 위치 추가\n",
    "    path_dt = 'drive/data/'\n",
    "    chatbot_data = pd.read_csv(path_dt + 'demendata.csv')\n",
    "    #데이터 밸런싱을 신경써서 섞기\n",
    "    chatbot_data_shuffled = chatbot_data.sample(frace=1).reset_index(drop=True)\n",
    "    #훈련데이터와 테스트데이터 나누기\n",
    "    train = chatbot_data_shuffled[:9000]\n",
    "    test = chatbot_data_shuffled[9000:]\n",
    "    #문장의 앞마다 [CLS], 문장 종료는 [SEP]를 붙여 인식시킨다.\n",
    "    #훈련데이터 인식과정\n",
    "    sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train.Q]\n",
    "    labels = train['label'].values     \n",
    "    preProcess(senetences, labels, \"train\")\n",
    "    #test데이터 인식과정\n",
    "    sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in test.Q]\n",
    "    labels = test['label'].values\n",
    "    preProcess(senetences, labels, \"test\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b7ac86",
   "metadata": {
    "id": "f2b7ac86"
   },
   "outputs": [],
   "source": [
    "#설명\n",
    "\n",
    "##################################################\n",
    "#단어를 토큰으로 만든뒤 정수 인코딩, 패딩 과정 수행\n",
    "#정수 인코딩 : 텍스트를 숫자로 바꾸는 기법\n",
    "## -> 각 단어를 고유한 정수에 매핑시키는 작업\n",
    "# 패딩 과정 : 문장의 길이를 하나로 통일하는 과정\n",
    "## -> 처리의 간편화를 위함, 하나로 통일할 때 부족한 배열의 값을 0으로 채우는 걸 제로 패딩이라고 함.\n",
    "## -> 여기서는 최대 128까지로 설정\n",
    "#기본적으로 자주 등장하는 단어를 단어 집합에 추가\n",
    "##################################################  \n",
    "##################################################\n",
    "## 어텐션이란? \n",
    "#쿼리가 주어졌을 때, 이 쿼리와 \n",
    "#여러 개의 키와의 유사도를 각각 구하고,\n",
    "#구한 유사도를 가중치로 설정하여 각각의 값을 구한 뒤\n",
    "#이 값들을 모두 가중합하여 반환하는 함수\n",
    "######\n",
    "#단어 벡터에 대해 쿼리, 키 값의 가중치 행렬을 곱해주어\n",
    "#쿼리, 키, 값 벡터를 얻어낸다.\n",
    "#그 후 쿼리 벡터에 대해 어텐션 스코어를 구하고,\n",
    "#이를 이용하여 모든 값 벡터를 가중합하여 어텐션 값을 구하게 된다.\n",
    "##################################################\n",
    "## 0 값을 가지는 패딩 토큰에 대해서 \n",
    "## 어텐션 연산을 불필요하게 수행하지 않도록 단어와 \n",
    "## 패딩 토큰을 구분할 수 있게 알려주는 것\n",
    "# 패딩된 데이터가 있을 때 패딩된 값은 0, 패딩되지 않은 단어는 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308ae515",
   "metadata": {
    "id": "308ae515"
   },
   "outputs": [],
   "source": [
    "##Test set 전처리\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "\n",
    "def getTokenizer():\n",
    "        global tokenizer\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "\n",
    "def preProcess(senetences, labels, mode):\n",
    "    input_ids, attention_masks = tokenizing(sentences)\n",
    "    \n",
    "    # 파이토치 텐서로 변환\n",
    "    if mode == \"test\": seperateDataTest(input_ids, labels, attention_masks)\n",
    "    elif mode == \"train\": seperateDataTrain(input_ids, labels, attention_masks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a206e56",
   "metadata": {
    "id": "2a206e56"
   },
   "outputs": [],
   "source": [
    "def tokenizing(sentences):\n",
    "    # Word 토크나이저 토큰화\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 시퀀스 설정 및 정수 인덱스 변환 & 패딩\n",
    "    MAX_LEN = 128\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크\n",
    "    attention_masks = []\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "        \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e539f9",
   "metadata": {
    "id": "12e539f9"
   },
   "outputs": [],
   "source": [
    "def seperateDataTest(input_ids, labels, attention_masks):\n",
    "    test_inputs = torch.tensor(input_ids)\n",
    "    test_labels = torch.tensor(labels)\n",
    "    test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    # 배치 사이즈 설정 및 데이터 설정\n",
    "    batch_size = 32\n",
    "    test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "    test_sampler = RandomSampler(test_data)\n",
    "    global test_dataloader\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6c6621",
   "metadata": {
    "id": "6e6c6621"
   },
   "outputs": [],
   "source": [
    "def seperateDataTrain(input_ids, labels, attention_masks):\n",
    "    #훈련셋과 검증셋, 훈련 라벨과 검증 라벨 생성\n",
    "    #input_ids와 labels를 분리\n",
    "    train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state= 2000, test_size=0.1)\n",
    "\n",
    "    #어텐션마스크를 분리\n",
    "    train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                     random_state=2000,\n",
    "                                     test_size=0.1)\n",
    "\n",
    "    #파이토치 텐서로 전환\n",
    "    train_inputs = torch.tensor(train_inputs)\n",
    "    train_labels = torch.tensor(train_labels)\n",
    "    train_masks = torch.tensor(train_masks)\n",
    "\n",
    "    validation_inputs = torch.tensor(validation_inputs)\n",
    "    validation_labels = torch.tensor(validation_labels)\n",
    "    validation_masks = torch.tensor(validation_masks)\n",
    "    \n",
    "    #배치사이즈를 설정하고 입력 데이터, 어텐션 마스크, 라벨을 하나의 데이터로 묶어 데이터 생성\n",
    "    batch_size = 32\n",
    "\n",
    "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    \n",
    "    global train_dataloader\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "    validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "    validation_sampler = SequentialSampler(validation_data)\n",
    "    \n",
    "    global validation_dataloader\n",
    "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0155b781",
   "metadata": {
    "id": "0155b781"
   },
   "outputs": [],
   "source": [
    "#BERT 모델 불러오기 전 GPU 디바이스 설정\n",
    "def setGPU() :\n",
    "    if torch.cuda.is_available():    \n",
    "        device = torch.device(\"cuda\")\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ef76d5",
   "metadata": {
    "id": "c3ef76d5"
   },
   "outputs": [],
   "source": [
    "#pretrain된 BERT 모델 불러오기\n",
    "def getBERT() :\n",
    "    setGPU()\n",
    "    model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "    model.cuda()\n",
    "    #하이퍼 파라미터\n",
    "    # 옵티마이저\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률(learning rate)\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "    # 에폭수\n",
    "    epochs = 8\n",
    "\n",
    "    # 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    #스케줄러 생성\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "    trainModel(model, epochs, optimizer, scheduler)\n",
    "    testModel(model, epochs, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9f058c",
   "metadata": {
    "id": "5f9f058c"
   },
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flatAccuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    \n",
    "    \n",
    "# 시간 표시 함수\n",
    "def formatTime(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae60a02",
   "metadata": {
    "id": "fae60a02"
   },
   "outputs": [],
   "source": [
    "##모델 학습\n",
    "\n",
    "#랜덤시드 고정\n",
    "def trainModel(model, epochs, optimizer, scheduler) :\n",
    "    seed_val = 42\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    #그래디언트 초기화\n",
    "    model.zero_grad()\n",
    "\n",
    "    # 학습\n",
    "    for epoch_i in range(0, epochs):\n",
    "    \n",
    "        # ========================================\n",
    "        #               Training\n",
    "        # ========================================\n",
    "    \n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        # 시작 시간 설정\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 로스 초기화\n",
    "        total_loss = 0\n",
    "\n",
    "        # 훈련모드로 변경\n",
    "        model.train()\n",
    "        \n",
    "        # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            # 경과 정보 표시\n",
    "            if step % 500 == 0 and not step == 0:\n",
    "                elapsed = formatTime(time.time() - t0)\n",
    "                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "            # 배치를 GPU에 넣음\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "            # 배치에서 데이터 추출\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "            # Forward 수행                \n",
    "            outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "            # 로스 구함\n",
    "            loss = outputs[0]\n",
    "\n",
    "            # 총 로스 계산\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Backward 수행으로 그래디언트 계산\n",
    "            loss.backward()\n",
    "\n",
    "            # 그래디언트 클리핑\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "            optimizer.step()\n",
    "\n",
    "            # 스케줄러로 학습률 감소\n",
    "            scheduler.step()\n",
    "\n",
    "            # 그래디언트 초기화\n",
    "            model.zero_grad()\n",
    "\n",
    "        # 평균 로스 계산\n",
    "        avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(formatTime(time.time() - t0)))\n",
    "        \n",
    "        # ========================================\n",
    "        #               Validation\n",
    "        # ========================================\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        #시작 시간 설정\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 평가모드로 변경\n",
    "        model.eval()\n",
    "\n",
    "        # 변수 초기화\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "        # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "        for batch in validation_dataloader:\n",
    "            # 배치를 GPU에 넣음\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "            # 배치에서 데이터 추출\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "            # 그래디언트 계산 안함\n",
    "            with torch.no_grad():     \n",
    "                # Forward 수행\n",
    "                outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "            # 로스 구함\n",
    "            logits = outputs[0]\n",
    "\n",
    "            # CPU로 데이터 이동\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "            # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "            tmp_eval_accuracy = flatAccuracy(logits, label_ids)\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "            nb_eval_steps += 1\n",
    "\n",
    "        print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "        print(\"  Validation took: {:}\".format(formatTime(time.time() - t0)))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4877a8",
   "metadata": {
    "id": "bc4877a8"
   },
   "outputs": [],
   "source": [
    "## 테스트셋 평가\n",
    "\n",
    "def testModel(model, epochs, optimizer, scheduler):\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            elapsed = formatTime(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "        # 출력 로직과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flatAccuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"Test took: {:}\".format(formatTime(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74229991",
   "metadata": {
    "id": "74229991"
   },
   "outputs": [],
   "source": [
    "##새로운 문장 테스트\n",
    "\n",
    "# 입력 데이터 변환\n",
    "def convert_input_data(sentences):\n",
    "    input_ids, attention_masks = tokenizing(sentences)\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks\n",
    "\n",
    "# 문장 테스트\n",
    "def testSentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    #model.eval()\n",
    "    getTokenizer()\n",
    "    #drive.mount('/content/drive')\n",
    "    setGPU()\n",
    "    model = torch.load(\"../src/dementia572.pt\")\n",
    "    #model = torch.load(\"/content/drive/MyDrive/ai/dementia572.pt\")\n",
    "    if torch.cuda.is_available():    \n",
    "        device = torch.device(\"cuda\")\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "            \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    print(logits)\n",
    "        \n",
    "\n",
    "    probabilities = softmax(logits, axis=1)\n",
    "    print(probabilities)\n",
    "    print(np.max(probabilities))\n",
    "    return np.argmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "x9bfZFZCeeN0",
   "metadata": {
    "id": "x9bfZFZCeeN0"
   },
   "outputs": [],
   "source": [
    "def readModel():\n",
    "    #drive.mount('/content/drive')\n",
    "    setGPU()\n",
    "    model = torch.load(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65d3cdbe",
   "metadata": {
    "id": "65d3cdbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-4' coro=<main() running at C:\\Users\\shinheeeul\\AppData\\Local\\Temp\\ipykernel_26316\\2892661335.py:14>>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import random\n",
    "\n",
    "#새로운 문장 들어왔을 시 치매인지 아닌지 반환\n",
    "# 1이면 치매, 0이면 일반\n",
    "def newSentence(S):\n",
    "    ans = testSentences([S])\n",
    "    return ans\n",
    "\n",
    "def randomVal():\n",
    "    return random.randrange(1,10)/10.0;\n",
    "\n",
    "async def main():\n",
    "    async with websockets.serve(echo, \"localhost\", 8765):\n",
    "        await asyncio.Future()  # 서버가 계속 실행되도록 대기\n",
    "\n",
    "async def echo(websocket, path):\n",
    "    async for message in websocket:\n",
    "        # 처리\n",
    "        print(message)\n",
    "        my_list = message.split(\"\\n\")\n",
    "        my_sum = 0.0;\n",
    "        for l in my_list:\n",
    "                val = newSentence(l);\n",
    "                my_sum += val;\n",
    "                print(\"val : \" + str(val))\n",
    "        await websocket.send(str(my_sum / len(my_list)))\n",
    "        print(\"success\")\n",
    "\n",
    "# 현재 실행 중인 이벤트 루프 가져오기\n",
    "loop = asyncio.get_event_loop()\n",
    "\n",
    "# 이벤트 루프에서 비동기 코드 실행\n",
    "loop.create_task(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80c9f817",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "80c9f817",
    "outputId": "81125b02-966e-4723-a52c-d8ff2fbf51af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "[[-0.54255205  0.5690955 ]]\n",
      "[[0.24756384 0.75243616]]\n",
      "0.75243616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"result\":\"COMPLETED\",\"message\":\"Succeeded\",\"token\":\"daa0dbcb06f44a948863d1d1199a35e8\",\"version\":\"ncp_v2_v2.1.6-d90fef3-20230420_v1.5.9_v4.1.5_ko_ncp_20221227_\",\"params\":{\"service\":\"ncp\",\"domain\":\"general\",\"lang\":\"ko\",\"completion\":\"sync\",\"diarization\":{\"enable\":true,\"speakerCountMin\":-1,\"speakerCountMax\":-1},\"boostings\":[],\"forbiddens\":\"\",\"wordAlignment\":true,\"fullText\":true,\"noiseFiltering\":true,\"resultToObs\":false,\"priority\":0,\"userdata\":{\"_ncp_DomainCode\":\"flashtest\",\"_ncp_DomainId\":4760,\"_ncp_TaskId\":13177378,\"_ncp_TraceId\":\"4b7dd398967747ff8da9f9c225f794d9\"}},\"progress\":100,\"keywords\":{},\"segments\":[{\"start\":380,\"end\":1690,\"text\":\"처음. 뵙겠습니다.\",\"confidence\":0.99133015,\"diarization\":{\"label\":\"1\"},\"speaker\":{\"label\":\"1\",\"name\":\"A\",\"edited\":false},\"words\":[[610,820,\"처음.\"],[820,1380,\"뵙겠습니다.\"]],\"textEdited\":\"처음. 뵙겠습니다.\"},{\"start\":2480,\"end\":5230,\"text\":\"안녕하세요. 저는 김혜원입니다.\",\"confidence\":0.9974096,\"diarization\":{\"label\":\"2\"},\"speaker\":{\"label\":\"2\",\"name\":\"B\",\"edited\":false},\"words\":[[2570,3320,\"안녕하세요.\"],[3930,4200,\"저는\"],[4230,5100,\"김혜원입니다.\"]],\"textEdited\":\"안녕하세요. 저는 김혜원입니다.\"},{\"start\":5230,\"end\":10240,\"text\":\"김혜영 씨시군요. 반갑습니다. 저는 신희을이라고 합니다.\",\"confidence\":0.94369423,\"diarization\":{\"label\":\"1\"},\"speaker\":{\"label\":\"1\",\"name\":\"A\",\"edited\":false},\"words\":[[6040,6410,\"김혜영\"],[6480,7090,\"씨시군요.\"],[7300,7990,\"반갑습니다.\"],[8180,8490,\"저는\"],[8560,9637,\"신희을이라고\"],[9637,10010,\"합니다.\"]],\"textEdited\":\"김혜영 씨시군요. 반갑습니다. 저는 신희을이라고 합니다.\"},{\"start\":10240,\"end\":20540,\"text\":\"그렇군요. 저는 건국대학교에 재학 중이고요 영어 영문학과를 전공하고 있습니다. 희은 님은 어떤 학과를 전공하고 계신가요\",\"confidence\":0.89219904,\"diarization\":{\"label\":\"2\"},\"speaker\":{\"label\":\"2\",\"name\":\"B\",\"edited\":false},\"words\":[[11450,12060,\"그렇군요.\"],[12570,12860,\"저는\"],[12970,13860,\"건국대학교에\"],[13890,14160,\"재학\"],[14230,14780,\"중이고요\"],[15310,15600,\"영어\"],[15600,16300,\"영문학과를\"],[16300,16847,\"전공하고\"],[16847,17400,\"있습니다.\"],[17910,18220,\"희은\"],[18230,18500,\"님은\"],[18550,18860,\"어떤\"],[18870,19280,\"학과를\"],[19280,19820,\"전공하고\"],[19820,20420,\"계신가요\"]],\"textEdited\":\"그렇군요. 저는 건국대학교에 재학 중이고요 영어 영문학과를 전공하고 있습니다. 희은 님은 어떤 학과를 전공하고 계신가요\"},{\"start\":20540,\"end\":23590,\"text\":\"저는 컴퓨터 공학부에 재학 중에 있습니다.\",\"confidence\":0.9579867,\"diarization\":{\"label\":\"1\"},\"speaker\":{\"label\":\"1\",\"name\":\"A\",\"edited\":false},\"words\":[[20950,21240,\"저는\"],[21310,21700,\"컴퓨터\"],[21700,22260,\"공학부에\"],[22260,22460,\"재학\"],[22490,22760,\"중에\"],[22760,23260,\"있습니다.\"]],\"textEdited\":\"저는 컴퓨터 공학부에 재학 중에 있습니다.\"},{\"start\":23730,\"end\":27740,\"text\":\"그렇습니까 컴퓨터 공학부는 재밌습니까\",\"confidence\":0.9759605,\"diarization\":{\"label\":\"2\"},\"speaker\":{\"label\":\"2\",\"name\":\"B\",\"edited\":false},\"words\":[[24180,24890,\"그렇습니까\"],[25820,26250,\"컴퓨터\"],[26260,26750,\"공학부는\"],[26780,27550,\"재밌습니까\"]],\"textEdited\":\"그렇습니까 컴퓨터 공학부는 재밌습니까\"},{\"start\":28430,\"end\":31930,\"text\":\"많이 힘듭니다. 영문학과는 좀 어떻습니까\",\"confidence\":0.9858872,\"diarization\":{\"label\":\"1\"},\"speaker\":{\"label\":\"1\",\"name\":\"A\",\"edited\":false},\"words\":[[29060,29330,\"많이\"],[29340,29910,\"힘듭니다.\"],[30040,30770,\"영문학과는\"],[30820,30970,\"좀\"],[30980,31710,\"어떻습니까\"]],\"textEdited\":\"많이 힘듭니다. 영문학과는 좀 어떻습니까\"},{\"start\":31930,\"end\":40130,\"text\":\"영어영문학과는 여러 가지 연리 문학과 문법 등을 배울 수 있어서 매우 흥미로운 학과입니다.\",\"confidence\":0.92450726,\"diarization\":{\"label\":\"2\"},\"speaker\":{\"label\":\"2\",\"name\":\"B\",\"edited\":false},\"words\":[[32140,33210,\"영어영문학과는\"],[33300,33570,\"여러\"],[33580,33930,\"가지\"],[34200,34850,\"연리\"],[34960,35530,\"문학과\"],[36300,36670,\"문법\"],[36800,37110,\"등을\"],[37120,37357,\"배울\"],[37357,37457,\"수\"],[37457,37830,\"있어서\"],[38020,38290,\"매우\"],[38290,38770,\"흥미로운\"],[38780,39490,\"학과입니다.\"]],\"textEdited\":\"영어영문학과는 여러 가지 연리 문학과 문법 등을 배울 수 있어서 매우 흥미로운 학과입니다.\"},{\"start\":40130,\"end\":42990,\"text\":\"그렇군요. 정말 흥미로운 학과인 것 같습니다.\",\"confidence\":0.9839488,\"diarization\":{\"label\":\"1\"},\"speaker\":{\"label\":\"1\",\"name\":\"A\",\"edited\":false},\"words\":[[40220,40770,\"그렇군요.\"],[40900,41190,\"정말\"],[41200,41710,\"흥미로운\"],[41740,42150,\"학과인\"],[42150,42290,\"것\"],[42290,42770,\"같습니다.\"]],\"textEdited\":\"그렇군요. 정말 흥미로운 학과인 것 같습니다.\"},{\"start\":42990,\"end\":49490,\"text\":\"그렇다면 어 영문학과를 복수 전공해보는 건 어떠세요.\",\"confidence\":0.9463597,\"diarization\":{\"label\":\"2\"},\"speaker\":{\"label\":\"2\",\"name\":\"B\",\"edited\":false},\"words\":[[43240,43850,\"그렇다면\"],[45960,46110,\"어\"],[46120,47330,\"영문학과를\"],[47660,47970,\"복수\"],[47970,48630,\"전공해보는\"],[48630,48750,\"건\"],[48750,49290,\"어떠세요.\"]],\"textEdited\":\"그렇다면 어 영문학과를 복수 전공해보는 건 어떠세요.\"},{\"start\":50830,\"end\":51390,\"text\":\"하하\",\"confidence\":0.4618271,\"diarization\":{\"label\":\"2\"},\"speaker\":{\"label\":\"2\",\"name\":\"B\",\"edited\":false},\"words\":[[50920,51230,\"하하\"]],\"textEdited\":\"하하\"},{\"start\":51730,\"end\":57690,\"text\":\"갑자기 그렇게 가버리면 그렇게 가버리시면 제가 좀 곤란합니다.\",\"confidence\":0.9573589,\"diarization\":{\"label\":\"1\"},\"speaker\":{\"label\":\"1\",\"name\":\"A\",\"edited\":false},\"words\":[[52000,52550,\"갑자기\"],[52680,53050,\"그렇게\"],[53100,53630,\"가버리면\"],[55100,55450,\"그렇게\"],[55520,56110,\"가버리시면\"],[56240,56510,\"제가\"],[56520,56670,\"좀\"],[56720,57390,\"곤란합니다.\"]],\"textEdited\":\"갑자기 그렇게 가버리면 그렇게 가버리시면 제가 좀 곤란합니다.\"},{\"start\":58380,\"end\":62390,\"text\":\"흥미가 있으신 줄 알았어요. 그렇다면 죄송합니다.\",\"confidence\":0.98216015,\"diarization\":{\"label\":\"2\"},\"speaker\":{\"label\":\"2\",\"name\":\"B\",\"edited\":false},\"words\":[[58710,59140,\"흥미가\"],[59140,59460,\"있으신\"],[59490,59640,\"줄\"],[59650,60280,\"알았어요.\"],[60470,61040,\"그렇다면\"],[61190,61920,\"죄송합니다.\"]],\"textEdited\":\"흥미가 있으신 줄 알았어요. 그렇다면 죄송합니다.\"}],\"text\":\"처음. 뵙겠습니다. 안녕하세요. 저는 김혜원입니다. 김혜영 씨시군요. 반갑습니다. 저는 신희을이라고 합니다. 그렇군요. 저는 건국대학교에 재학 중이고요 영어 영문학과를 전공하고 있습니다. 희은 님은 어떤 학과를 전공하고 계신가요 저는 컴퓨터 공학부에 재학 중에 있습니다. 그렇습니까 컴퓨터 공학부는 재밌습니까 많이 힘듭니다. 영문학과는 좀 어떻습니까 영어영문학과는 여러 가지 연리 문학과 문법 등을 배울 수 있어서 매우 흥미로운 학과입니다. 그렇군요. 정말 흥미로운 학과인 것 같습니다. 그렇다면 어 영문학과를 복수 전공해보는 건 어떠세요. 하하 갑자기 그렇게 가버리면 그렇게 가버리시면 제가 좀 곤란합니다. 흥미가 있으신 줄 알았어요. 그렇다면 죄송합니다.\",\"confidence\":0.94443166,\"speakers\":[{\"label\":\"1\",\"name\":\"A\",\"edited\":false},{\"label\":\"2\",\"name\":\"B\",\"edited\":false}\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "[[-1.8092976  1.9870512]]\n",
      "[[0.02195955 0.97804046]]\n",
      "0.97804046\n",
      "val : 1\n",
      "success\n",
      "처음. 뵙겠습니다.\n",
      "김혜영 씨시군요. 반갑습니다. 저는 신희을이라고 합니다.\n",
      "저는 컴퓨터 공학부에 재학 중에 있습니다.\n",
      "많이 힘듭니다. 영문학과는 좀 어떻습니까\n",
      "그렇군요. 정말 흥미로운 학과인 것 같습니다.\n",
      "갑자기 그렇게 가버리면 그렇게 가버리시면 제가 좀 곤란합니다.\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "[[-1.6343715  1.5239459]]\n",
      "[[0.04076479 0.95923525]]\n",
      "0.95923525\n",
      "val : 1\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "[[-2.45749    2.5943522]]\n",
      "[[0.00635687 0.99364316]]\n",
      "0.99364316\n",
      "val : 1\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "[[-2.2937498  2.420072 ]]\n",
      "[[0.00889068 0.9911094 ]]\n",
      "0.9911094\n",
      "val : 1\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "[[-2.4303045  2.4120917]]\n",
      "[[0.00782639 0.9921737 ]]\n",
      "0.9921737\n",
      "val : 1\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "[[-2.95992    2.9506147]]\n",
      "[[0.00270341 0.99729663]]\n",
      "0.99729663\n",
      "val : 1\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce MX450\n",
      "[[-2.936951  2.953345]]\n",
      "[[0.00275853 0.9972415 ]]\n",
      "0.9972415\n",
      "val : 1\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "#def getModel():\n",
    "    #readFile()\n",
    "    #getTokenizer()\n",
    "    #getBERT()\n",
    "\n",
    "#학습된 모델 가져오기\n",
    "#getModel()\n",
    "#readModel()\n",
    "\n",
    "#새로운 문장 들어왔을 시 치매인지 아닌지 반환\n",
    "# 0이면 치매, 1이면 일반\n",
    "def newSentence(S):\n",
    "    ans = testSentences([S])\n",
    "    return ans\n",
    "\n",
    "def Test():\n",
    "    return \"TEST\"\n",
    "\n",
    "#newSentence(\"난 분명 대학생이었는데\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be350d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "history_visible": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
